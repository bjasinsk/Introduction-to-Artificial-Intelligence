# Introduction-to-Artificial-Intelligence lab-1

Exercise 1

The aim of the exercise is to minimise the objective function and compare the results for the fastest gradient descent method and Newton's method.

The objective function is a Himmelblau function of the form:

f(x,y) = (x*x+y-11)^2 + (x+y*y-7)^2 , -5 <= x <= 5, -5 <= y <= 5

Libraries used in the implementation of the solution:

- autograd
- numpy
- matplotlib
- time
- random
- pandas

In the solution I provided, I used the autograd library to calculate the gradient and hessian.
